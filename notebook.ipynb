{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "854025f0c407"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_google_community import BigQueryVectorStore\n",
    "from langchain_google_vertexai import VertexAI, VertexAIEmbeddings\n",
    "from google.cloud import bigquery\n",
    "import vertexai\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=config.PROJECT_ID, location=config.REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDSM2ZQa8eBs"
   },
   "source": [
    "## Add documents to `BigQueryVectorStore`\n",
    "\n",
    "This step ingests and parse PDF documents, split them, generate embeddings and add the embeddings to the vector store. The document corpus used as dataset is a collection of owners car manual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3hRmLiY2O0w"
   },
   "source": [
    "### Create the VertexAI Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2tRYGd_Mv_ix"
   },
   "outputs": [],
   "source": [
    "embedding_model = VertexAIEmbeddings(\n",
    "    model_name=\"textembedding-gecko@latest\", project=config.PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UNEClQQjjRcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://rag-llm-documents/file.pdf...\n",
      "/ [1 files][328.9 KiB/328.9 KiB]                                                \n",
      "Operation completed over 1 objects/328.9 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# Copy the file to the current path\n",
    "!gsutil cp \"gs://$config.GCS_BUCKET_DOCS/file.pdf\" ./data/file.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7kYw66EohYza"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of documents loaded (pre-chunking) = 22\n"
     ]
    }
   ],
   "source": [
    "# Ingest PDF files\n",
    "loader = PyPDFLoader(\"data/file.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Add document name and source to the metadata\n",
    "for document in documents:\n",
    "    doc_md = document.metadata\n",
    "    document_name = doc_md[\"source\"].split(\"/\")[-1]\n",
    "    # derive doc source from Document loader\n",
    "    doc_source_prefix = \"/\".join(config.GCS_BUCKET_DOCS.split(\"/\")[:3])\n",
    "    doc_source_suffix = \"/\".join(doc_md[\"source\"].split(\"/\")[4:-1])\n",
    "    source = f\"{doc_source_prefix}/{doc_source_suffix}\"\n",
    "    document.metadata = {\"source\": source, \"document_name\": document_name}\n",
    "\n",
    "print(f\"# of documents loaded (pre-chunking) = {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8J7hQkVmkB1"
   },
   "source": [
    "Verify document metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZA9HDA0mnWW"
   },
   "source": [
    "## Chunk documents - `TextSplitter`\n",
    "\n",
    "Split the documents to smaller chunks. When splitting the document, ensure a few chunks can fit within the context length of LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of documents = 60\n"
     ]
    }
   ],
   "source": [
    "# split the documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Add chunk number to metadata\n",
    "for idx, split in enumerate(doc_splits):\n",
    "    split.metadata[\"chunk\"] = idx\n",
    "\n",
    "print(f\"# of documents = {len(doc_splits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'rag-llm-documents/', 'document_name': 'file.pdf', 'chunk': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_splits[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure there is no previous Vector Store\n",
    "dataset = f\"{config.PROJECT_ID}.{config.DATASET}\"\n",
    "dataset_object = bigquery.Dataset(dataset)\n",
    "client = bigquery.Client(project=config.PROJECT_ID, location=config.REGION)\n",
    "client.delete_dataset(dataset_object, delete_contents=True, not_found_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gLxHuLY1lxrS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery table rag-llm-428210.sample_app.fixmycar initialized/validated as persistent storage. Access via BigQuery console:\n",
      " https://console.cloud.google.com/bigquery?project=rag-llm-428210&ws=!1m5!1m4!4m3!1srag-llm-428210!2ssample_app!3sfixmycar\n"
     ]
    }
   ],
   "source": [
    "bq_store = BigQueryVectorStore(\n",
    "    project_id=config.PROJECT_ID,\n",
    "    location=config.REGION,\n",
    "    dataset_name=config.DATASET,\n",
    "    table_name=config.TABLE,\n",
    "    embedding=embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17cgWCFRlxrS"
   },
   "source": [
    "### Add documents to the store\n",
    "\n",
    "Note: If you have precomputed embeddings, you can add text, embeddings and potential metadata using the method `add_texts_with_embeddings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_TXggBP9lxrT"
   },
   "outputs": [],
   "source": [
    "doc_ids = bq_store.add_documents(doc_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4Zz3PUFlxrT"
   },
   "source": [
    "### Get a langchain retriever\n",
    "The retriever will be used in a LangChain Chain to find the most similar documents for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "F9mSL5o-lxrT"
   },
   "outputs": [],
   "source": [
    "langchain_retriever = bq_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWroxQMflxrT"
   },
   "source": [
    "### Compose a LangChain Chain\n",
    "\n",
    "We are going to use the [`RetrievalQA` chain](https://python.langchain.com/docs/modules/chains/popular/vector_db_qa)\n",
    "There are several different chain types available, listed [here](https://docs.langchain.com/docs/components/chains/index_related_chains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-eZsLYIPlxrT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################ Final Answer ################\n",
      "\n",
      "When calling the emergency roadside assistance, you should be prepared to provide the following information: \n",
      "* Your name and contact information\n",
      "* Your vehicle's make, model, and year\n",
      "* Your vehicle's location\n",
      "* The nature of the emergency \n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm = VertexAI(model_name=\"gemini-1.5-flash\")\n",
    "\n",
    "search_query = \"What should I do when calling the emergency roadside assistance?\"  # @param {type:\"string\"}\n",
    "\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=langchain_retriever\n",
    ")\n",
    "response = retrieval_qa.invoke(search_query)\n",
    "print(\"\\n################ Final Answer ################\\n\")\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a4e033321ad"
   },
   "source": [
    "## Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21f2a7432655"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "dataset = f\"{config.PROJECT_ID}.{config.DATASET_ID}\"\n",
    "dataset_object = bigquery.Dataset(dataset)\n",
    "client.delete_dataset(dataset_object, delete_contents=True, not_found_ok=True)\n",
    "\n",
    "vertex_fs.feature_view.delete()\n",
    "vertex_fs.online_store.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "rag_qna_with_bq_and_featurestore.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (marcoenv)",
   "language": "python",
   "name": "marcoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
